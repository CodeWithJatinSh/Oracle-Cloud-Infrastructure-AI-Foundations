{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea75de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "Feature columns: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Target classes: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Training samples: 120\n",
      "Testing samples: 30\n",
      "\n",
      "Model training complete!\n",
      "\n",
      "Model Evaluation:\n",
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Predictions for new samples: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Prediction for single sample [5.1, 3.5, 1.4, 0.2]: setosa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\sohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 1: Import Required Libraries\n",
    "# ===============================\n",
    "\n",
    "# Pandas: for handling dataset\n",
    "import pandas as pd  \n",
    "\n",
    "# Numpy: for numerical operations like arrays\n",
    "import numpy as np  \n",
    "\n",
    "# scikit-learn (sklearn): machine learning library\n",
    "from sklearn.model_selection import train_test_split   # to split dataset into train and test\n",
    "from sklearn.preprocessing import StandardScaler       # to scale/normalize features\n",
    "from sklearn.linear_model import LogisticRegression    # our ML model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # evaluation tools\n",
    "\n",
    "# ===============================\n",
    "# Step 2: Load Dataset\n",
    "# ===============================\n",
    "\n",
    "# Iris dataset has 150 rows (flowers) and 5 columns:\n",
    "# - sepal_length, sepal_width, petal_length, petal_width (features)\n",
    "# - species (label/target)\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# ===============================\n",
    "# Step 3: Split Features (X) and Target (y)\n",
    "# ===============================\n",
    "\n",
    "# Features (inputs) are the measurements (lengths & widths of petals and sepals)\n",
    "X = data.drop(\"species\", axis=1)   # all columns except 'species'\n",
    "\n",
    "# Target (output) is the species of the flower\n",
    "y = data[\"species\"]\n",
    "\n",
    "print(\"\\nFeature columns:\", X.columns.tolist())\n",
    "print(\"Target classes:\", y.unique())\n",
    "\n",
    "# ===============================\n",
    "# Step 4: Train-Test Split\n",
    "# ===============================\n",
    "\n",
    "# Why? Because we need to train the model on some data and test it on unseen data\n",
    "# test_size=0.2 means 20% test, 80% train\n",
    "# random_state=42 ensures same split every time (reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining samples:\", X_train.shape[0])\n",
    "print(\"Testing samples:\", X_test.shape[0])\n",
    "\n",
    "# ===============================\n",
    "# Step 5: Feature Scaling\n",
    "# ===============================\n",
    "\n",
    "# Why scale? Because logistic regression uses mathematical optimization.\n",
    "# If features are on very different scales, training becomes harder.\n",
    "# StandardScaler converts data to mean=0, standard deviation=1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Only transform test data (never fit on test data to avoid data leakage)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ===============================\n",
    "# Step 6: Train Logistic Regression Model\n",
    "# ===============================\n",
    "\n",
    "# Logistic Regression is a classification algorithm.\n",
    "# Even though it has \"regression\" in name, it predicts categories (classes).\n",
    "# It works by estimating probabilities using the logistic (sigmoid) function.\n",
    "\n",
    "model = LogisticRegression(max_iter=200)  # max_iter ensures convergence\n",
    "model.fit(X_train_scaled, y_train)        # train the model\n",
    "\n",
    "print(\"\\nModel training complete!\")\n",
    "\n",
    "# ===============================\n",
    "# Step 7: Evaluate Model on Test Data\n",
    "# ===============================\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)   # predict on test data\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))   # % correct predictions\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ===============================\n",
    "# Step 8: Make Predictions on New Samples\n",
    "# ===============================\n",
    "\n",
    "# Example new flowers (unseen data)\n",
    "# Each row = [sepal_length, sepal_width, petal_length, petal_width]\n",
    "sample_data = np.array([\n",
    "    [4.9, 3.0, 1.2, 0.1],   # looks like Iris-setosa\n",
    "    [6.7, 3.1, 4.7, 1.5],   # looks like Iris-versicolor\n",
    "    [5.8, 2.7, 5.1, 1.9]    # looks like Iris-virginica\n",
    "])\n",
    "\n",
    "# Scale new samples the same way\n",
    "sample_scaled = scaler.transform(sample_data)\n",
    "\n",
    "# Predict species\n",
    "predictions = model.predict(sample_scaled)\n",
    "\n",
    "print(\"\\nPredictions for new samples:\", predictions)\n",
    "\n",
    "# ===============================\n",
    "# Step 9: Predict a Single Sample\n",
    "# ===============================\n",
    "\n",
    "single_sample = np.array([5.1, 3.5, 1.4, 0.2]).reshape(1, -1)   # reshape required for single input\n",
    "single_sample_scaled = scaler.transform(single_sample)\n",
    "single_prediction = model.predict(single_sample_scaled)\n",
    "\n",
    "print(\"\\nPrediction for single sample [5.1, 3.5, 1.4, 0.2]:\", single_prediction[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
